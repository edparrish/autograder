# Design

## Introduction

Autograde5 is the fifth major version of a testing framework for automatically grading student homework for Computer Science classes. The Autograder work originally started around August 2003. Autograder was inspired by JUnit as originally written by Erich Gamma and Kent Beck. Its purpose is to automatically grade and evaluate student programming assignments while facilitating human intervention and supporting decisions on the final grade for an assignment.

## Design Goals

- Interface with various course management systems, especially Canvas
- Process student assignment submissions singly or as a group
- Test student source code files using regular expressions
- Test student source code files using custom test programs
- Test student code by applying known input and capturing output
- Test student code output using regular expressions
- Aggregate errors and analyze scores statiscally
- Compare student files to detect plagarism
- Facilitate human review of automatic grading with ability to override results
â€“ Basic assessment management reporting facility
- Robograde option where students promptly get automated feedback (new)

## General Grading Process

1. Download submissions from a Learning Management System (LMS) like Blackboard and Canvas. (Manager UI)
2. Organize data into assignment and student folders. (`foldermaker.php`)
3. Setup each student folder by unzipping files, etc. (`Preparer`)
4. Run automatic grading using scripts for each requirement: (`Grader`)
  a. Select file(s) to grade. (`FileFinder`)
  b. Load file contents and filter as needed. (`FileContents`)
  c. Apply test cases assigning points and message to each error. (`TestCase`)
  d. Aggregate and analyze individual results. (`Evaluator`)
5. Facilitate human review and correct machine evaluation errors. (`Reviewer`)
6. Evaluate and summarize aggregate results. (`Analyzer`)
7. Report results back to student. (Manager UI)

## High-Level Design

Autograde5 is based on a series of test cases implemented as subclasses of `TestCase`. Each of the test cases are reusable on many different assignments. A grading framework enables the application of these test cases.

The grading framework is controlled by the `Grader` object. The `Grader` object has a `runTest()` method that runs tests on each student and creates a grade log of results.

    function runTest() {
        $this->startTest();
        $this->dit = $this->dl->iterator();
        while ($this->dit->hasNext()) {
            $this->dir = $this->dit->next();
            $this->preTest();
            $this->test();
            $this->postTest();
        }
        $this->finishTest();
    }

The `startTest()` method is called to setup or fixture the testing. Specifically, `startTest()` initializes the clock, logging system, scoring system and other record keeping aspects of the test. The `DirectoryIterator` is also initialized after `startTest()`. The `finishTest()` method tears down the test environment.

Each student test has a `pretest()` to prepare the test fixturing, a `test()` method overriden in each homework script, and a `postTest()` method to clean up the test fixtures. The `test()` method is where the test cases are applied.

Test methods for each student:

    $this->preTest(); // setup
    $this->test();    // apply test cases
    $this->postTest();// teardown/finish tests

Usually all the testing is performed in the `test()` method of a `Grader` subclass, which I usually name `GradeRunner`. The usual grading process is:

1. Find the file to grade.
2. Compile source code (for compiled languages) saving results in a log file.
3. Run compiled program with defined input and save the output in a log file.
4. Check the output and comment on problems.
5. Check the source code file for required elements.
6. After finishing a test suite, run an evaluator to add up points and make an automated comment.
7. At the end of the test, generate an overall message commenting on the overall assignment performance.

At the end of the test, the test results and log files are collected into one file named `grade.log`.

The process for running test cases is:

1. Load each file into `FileContents` object.
2. Apply filters to `FileContents` object to remove extranous info such as comments
3. Apply `TestCases` using using `Grader` methods `run()`, `pass()`, `fail()`, and `passFail()`:
    - `run()`: run test without applying message or points.
    - `pass()`: apply message and points if the test case asserts `TRUE`
    - `fail()`: apply message and points if the test case asserts `FALSE`
    - `passFail()`: apply one message and points if `TRUE` and another set if `FALSE`

After individual tests then run group tests such as cheating detection like MOSS.

## Module Design Description

AutoGrader version 5 has six main modules organized as classes:
1. [`Preparer`](#1-preparer): Downloads and sets-up student files for grading and review.
2. [`Grader`](#2-grader): Runs individual tests and records errors, generating a grade log.
3. [`TestCase`](#3-testcase): Apply a test case to a file.
4. [`Evaluator`](#4-evaluator): Evaluates test results, essentially converting them into scores.
5. [`TestResult`](#5-testresult): Collects data from test cases for use by evaluators.
6. [`Reviewer`](#6-reviewer): Iterates through the student files and grading results, allowing changes to be made by a human.
7. [`Analyzer`](#7-analyzer): Analyzes and reports aggregate data and statistics.

These modules use other classes including:
1. `DirectoryIterator`: Responsible for accessing each student's work.
2. `TestResult`: Maintains the test results such as error lists.

The modules are discussed in the following sections.

### 1. `Preparer`
Responsible for:
1. Downloading files from various sources (`manager.html`)
2. Setting up directories for student work (`foldermaker.php`)
3. Unzipping files, recursively tracing through directory structures
4. Reporting problems found in the set up process for human review and intervention

### 2. `Grader`

The Grader class coordinates the access to student work and provides a facade to test and evaluation functions. `TestCase` objects test the student work and save results in a `TestResult`. `Evaluator` classes evaluate the tests and provide a score.

### 3. `TestCase`

The `TestCase` class is an abstract superclass for various test classes and supplies a `run()` method that in turn calls a `runTest()` method. Each `TestCase` subclass implements a constructor and a `runTest()` method. The constructor initializes the object and the actual test is implemented starting in the `runTest()` method.

### 4. `Evaluator`

The `Evaluator` class is an abstract superclass for various types of evaluators. It provides a consistent interface for performing an evaluation by the `Grader`. This allows reusing evaluation techniques, but still choosing different techniques for different parts of an assignment.

All evaluators compute and return a score based on a `TestResult`. In addition, `Evaluator` classes list problems found to the grade.log file. `Evaluator` classes include:
- `CompileEvaluator`
- `ReadMeEvaluator`
- `StyleEvaluator`
- `ValueEvaluator`

### 5. `TestResult`

A `TestResult` collects data from `TestCase` classes and provides an interface to `Evaluator` classes. Using a `TestResult` decouples the test and evaluation functions, allowing the grader to aggregate test results before evaluation. A `TestResult` has both a properties list and a messages list. The properties allow storage of any `name=value` pairs. The message list provides messages that are displayed to the student.

### 6. `Reviewer`

Iterates through each assignment, allowing a human grader to review the automatically produced results. Changes can be made in the grade log file.

### 7. `Analyzer`

Analyzes and reports aggregate data and statistics.

## Features Added in Autograder5 (Started 6/12/16)

- Now runs student programs so processes can timeout and be stopped. This helps the script to continue when a student has an infinite loops or other problem. -Unfortunately, not 100% successful if the code has a very tight loop.

- Much of the grading system uses the command line. In Autograder5, added a Web-based user interface to support downloading assignments, running grading scripts, and uploading feedback. The feature automates Canvas download and upload.

- Added `FileContents` to load files into memory and apply filters. This allows the system to remove unwanted code like comments (`$fc->stripComments()`). A `FileContents` object can extract parts of a file and has other features to make it easier to test for specific code.

- Improved README detection in `Grader` to better report missing README.txt files.

- Refactored `TestCompileCPP` to make it easier to use.

- Added and updated documents in docs folder:
    - README.txt: Intro and list of useage documentation
    - install.txt: Installing the autograde5 system
    - grading.txt: Tutorial on writing grading scripts
    - design.txt: Design overview and notes
    - cookbook.txt: Common grading script techniques and snippets
